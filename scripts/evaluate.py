import config
import os
import sys
import numpy as np
from stable_baselines3 import PPO
import argparse
import time

# å…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®import
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.f1_env import F1TenthRL

def main():
    parser = argparse.ArgumentParser(description='F1Tenth Model Benchmark Evaluator')
    parser.add_argument('--episodes', type=int, default=10, help='è©•ä¾¡ã™ã‚‹ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°')
    parser.add_argument('--max_steps', type=int, default=2000, help='1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚ãŸã‚Šã®æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°')
    parser.add_argument('--model', type=str, default=None, help='ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹(æ‹¡å¼µå­ãªã—)')
    args = parser.parse_args()

    # ç’°å¢ƒã®åˆæœŸåŒ–
    env = F1TenthRL(config.MAP_PATH)
    
    # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    target_model = args.model if args.model else config.MODEL_PATH
    if not target_model.endswith(".zip"):
        target_model += ".zip"
    
    if os.path.exists(target_model):
        model = PPO.load(target_model, device=config.DEVICE)
        print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {target_model}")
    else:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {target_model}")
        return

    print(f"\n--- ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹ ({args.episodes} ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰) ---")
    
    results = {
        "steps": [],
        "rewards": [],
        "avg_speeds": [],
        "collisions": 0,
        "success": 0
    }

    start_time = time.time()

    for ep in range(args.episodes):
        obs = env.reset()
        done = False
        ep_reward = 0
        ep_steps = 0
        speeds = []
        
        while not done and ep_steps < args.max_steps:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, done, info = env.step(action)
            
            # é€Ÿåº¦ã®å–å¾—
            try:
                speed = env.env.sim.agents[0].state[3]
                speeds.append(speed)
            except:
                pass
                
            ep_reward += reward
            ep_steps += 1
        
        # è¨˜éŒ²
        results["steps"].append(ep_steps)
        results["rewards"].append(ep_reward)
        results["avg_speeds"].append(np.mean(speeds) if speeds else 0)
        
        if done:
            results["collisions"] += 1
            status = "Collision"
        else:
            results["success"] += 1
            status = "Success (Max Steps)"
            
        print(f"Episode {ep+1:02d}: Steps={ep_steps:4d}, Reward={ep_reward:7.1f}, Speed={np.mean(speeds):.2f}m/s, {status}")

    total_time = time.time() - start_time
    
    # é›†è¨ˆçµæœã®è¡¨ç¤º
    print("\n" + "="*40)
    print("ğŸ“Š æœ€çµ‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ")
    print("="*40)
    print(f"ãƒ¢ãƒ‡ãƒ«: {os.path.basename(target_model)}")
    print(f"ç·è¨ˆæ™‚é–“: {total_time:.2f} ç§’")
    print(f"æˆåŠŸç‡ (å®Œèµ°): {results['success'] / args.episodes * 100:.1f}%")
    print(f"è¡çªç‡: {results['collisions'] / args.episodes * 100:.1f}%")
    print("-"*40)
    print(f"å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—æ•°: {np.mean(results['steps']):.1f} steps")
    print(f"å¹³å‡ç´¯ç©å ±é…¬: {np.mean(results['rewards']):.1f}")
    print(f"å…¨ä½“å¹³å‡é€Ÿåº¦: {np.mean(results['avg_speeds']):.2f} m/s")
    print(f"æœ€é«˜å¹³å‡é€Ÿåº¦: {np.max(results['avg_speeds']):.2f} m/s")
    print("="*40)

if __name__ == '__main__':
    main()
